{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c7b35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load datasets\n",
    "df_train = pd.read_csv(\"train(43).csv\")\n",
    "path = kagglehub.dataset_download(\"fedesoriano/stroke-prediction-dataset\")\n",
    "df_kaggle = pd.read_csv(f\"{path}/healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "# 2. Add 'stroke' column to df_test if not present\n",
    "if 'stroke' not in df_kaggle.columns:\n",
    "    df_kaggle['stroke'] = None  # (In this case, Kaggle data already has 'stroke')\n",
    "\n",
    "# 3. Align columns in both dataframes\n",
    "common_cols = list(set(df_train.columns) | set(df_kaggle.columns))\n",
    "df_train = df_train.reindex(columns=common_cols)\n",
    "df_kaggle = df_kaggle.reindex(columns=common_cols)\n",
    "\n",
    "# 4. Concatenate dataframes\n",
    "df = pd.concat([df_train, df_kaggle], ignore_index=True)\n",
    "\n",
    "# 5. Convert categorical features to numeric codes\n",
    "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
    "df['ever_married'] = df['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "df['Residence_type'] = df['Residence_type'].map({'Urban': 1, 'Rural': 0})\n",
    "df['smoking_status'] = df['smoking_status'].map({\n",
    "    'never smoked': 0,\n",
    "    'formerly smoked': 0.5,\n",
    "    'smokes': 1\n",
    "})\n",
    "\n",
    "# 6. One-hot encode the work_type feature\n",
    "df = pd.get_dummies(df, columns=['work_type'], prefix='work')\n",
    "\n",
    "# 7. Remove any rows without a stroke label\n",
    "df = df[df['stroke'].notna()]\n",
    "df['stroke'] = df['stroke'].astype(int)\n",
    "\n",
    "# 8. Impute missing numeric values using IterativeImputer (MICE)\n",
    "mice_imputer = IterativeImputer(random_state=42)\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('stroke')\n",
    "df[numeric_cols] = mice_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# 9. Train-test split (80/20)\n",
    "X = df.drop(columns=['stroke'])\n",
    "y = df['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 10. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 11. Balance the training set using SMOTE + Tomek Links\n",
    "sampler = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6adc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Accuracy: 0.7468563182848897\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[7094 2408]\n",
      " [  48  152]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9933    0.7466    0.8524      9502\n",
      "           1     0.0594    0.7600    0.1101       200\n",
      "\n",
      "    accuracy                         0.7469      9702\n",
      "   macro avg     0.5263    0.7533    0.4813      9702\n",
      "weighted avg     0.9740    0.7469    0.8371      9702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 12. Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 13. Evaluate on test set\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_lr, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411a8ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Accuracy: 0.9727891156462585\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[9348  154]\n",
      " [ 110   90]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9884    0.9838    0.9861      9502\n",
      "           1     0.3689    0.4500    0.4054       200\n",
      "\n",
      "    accuracy                         0.9728      9702\n",
      "   macro avg     0.6786    0.7169    0.6957      9702\n",
      "weighted avg     0.9756    0.9728    0.9741      9702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_rf, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c352410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Accuracy: 0.8297258297258298\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[7932 1570]\n",
      " [  82  118]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9898    0.8348    0.9057      9502\n",
      "           1     0.0699    0.5900    0.1250       200\n",
      "\n",
      "    accuracy                         0.8297      9702\n",
      "   macro avg     0.5298    0.7124    0.5153      9702\n",
      "weighted avg     0.9708    0.8297    0.8896      9702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gb))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_gb, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88da4713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [17:47:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Accuracy: 0.9575345289631004\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[9236  266]\n",
      " [ 146   54]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9844    0.9720    0.9782      9502\n",
      "           1     0.1688    0.2700    0.2077       200\n",
      "\n",
      "    accuracy                         0.9575      9702\n",
      "   macro avg     0.5766    0.6210    0.5929      9702\n",
      "weighted avg     0.9676    0.9575    0.9623      9702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_xgb, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536e0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 37941, number of negative: 37941\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2156\n",
      "[LightGBM] [Info] Number of data points in the train set: 75882, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "📊 Accuracy: 0.9475365903937333\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[9148  354]\n",
      " [ 155   45]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9833    0.9627    0.9729      9502\n",
      "           1     0.1128    0.2250    0.1503       200\n",
      "\n",
      "    accuracy                         0.9475      9702\n",
      "   macro avg     0.5481    0.5939    0.5616      9702\n",
      "weighted avg     0.9654    0.9475    0.9560      9702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb_model = LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_lgb))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgb))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_lgb, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd5663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6931 val_loss=0.0000 scale=2.0000 norm=4.0000\n",
      "[iter 100] loss=0.4302 val_loss=0.0000 scale=2.0000 norm=3.3765\n",
      "[iter 200] loss=0.3917 val_loss=0.0000 scale=1.0000 norm=1.6860\n",
      "[iter 300] loss=0.3801 val_loss=0.0000 scale=1.0000 norm=1.6839\n",
      "[iter 400] loss=0.3672 val_loss=0.0000 scale=1.0000 norm=1.6727\n",
      "📊 Accuracy: 0.7692228406514121\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[7313 2189]\n",
      " [  50  150]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9932    0.7696    0.8672      9502\n",
      "           1     0.0641    0.7500    0.1182       200\n",
      "\n",
      "    accuracy                         0.7692      9702\n",
      "   macro avg     0.5287    0.7598    0.4927      9702\n",
      "weighted avg     0.9741    0.7692    0.8518      9702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "   # install NGBoost library\n",
    "from ngboost import NGBClassifier\n",
    "\n",
    "ngb_model = NGBClassifier(random_state=42)\n",
    "ngb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred_ngb = ngb_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_ngb))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ngb))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_ngb, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa909076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_accuracy = 0.87333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Accuracy: 0.8733250876108019\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[8359 1143]\n",
      " [  86  114]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9898    0.8797    0.9315      9502\n",
      "           1     0.0907    0.5700    0.1565       200\n",
      "\n",
      "    accuracy                         0.8733      9702\n",
      "   macro avg     0.5403    0.7249    0.5440      9702\n",
      "weighted avg     0.9713    0.8733    0.9155      9702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # install the PyTorch TabNet implementation\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "tabnet_model = TabNetClassifier(seed=42, verbose=0)\n",
    "tabnet_model.fit(X_resampled, y_resampled, eval_set=[(X_test_scaled, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=100)\n",
    "\n",
    "y_pred_tab = tabnet_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_tab))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tab))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_tab, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075b94b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [17:57:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 37941, number of negative: 37941\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2156\n",
      "[LightGBM] [Info] Number of data points in the train set: 75882, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "📊 Accuracy: 0.935374149659864\n",
      "\n",
      "🧩 Confusion Matrix:\n",
      " [[8986  516]\n",
      " [ 111   89]]\n",
      "\n",
      "📋 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9878    0.9457    0.9663      9502\n",
      "           1     0.1471    0.4450    0.2211       200\n",
      "\n",
      "    accuracy                         0.9354      9702\n",
      "   macro avg     0.5675    0.6953    0.5937      9702\n",
      "weighted avg     0.9705    0.9354    0.9509      9702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONOR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 14. Create a voting ensemble of all trained models\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('rf', rf_model),\n",
    "        ('gb', gb_model),\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgb', lgb_model),\n",
    "        # ('ngb', ngb_model),  # исключён\n",
    "        # ('tabnet', tabnet_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 15. Evaluate the ensemble on the test set\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "print(\"📊 Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "print(\"\\n🧩 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ensemble))\n",
    "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred_ensemble, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17465078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
